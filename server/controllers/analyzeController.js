import axios from 'axios';
import { Octokit } from '@octokit/rest';
import dotenv from 'dotenv';

dotenv.config();

// Debug environment variables
console.log('Environment check in analyzeController:');
console.log('GEMINI_API_KEY length:', process.env.GEMINI_API_KEY?.length);

if (!process.env.GEMINI_API_KEY) {
    throw new Error('GEMINI_API_KEY environment variable is not set');
}

const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const GEMINI_ANALYSIS_ENDPOINT = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GEMINI_API_KEY}`;
const GEMINI_FIX_ENDPOINT = `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${GEMINI_API_KEY}`;

const octokit = new Octokit({
    auth: process.env.GITHUB_TOKEN || process.env.PAT_TOKEN
});

export const analyze = async (req, res) => {
    try {
        const { repo, commitId, owner, branch, repoLanguage } = req.body;
        console.log('Analyze request received:', { repo, commitId, owner, branch, repoLanguage });

        // Handle repo in format owner/repo
        let repoOwner = owner;
        let repoName = repo;
        if (repo.includes('/')) {
            [repoOwner, repoName] = repo.split('/');
        }

        if (!repoName || !repoOwner) {
            console.error('Missing required parameters:', { repo: repoName, owner: repoOwner });
            return res.status(400).json({ error: 'Missing required parameters' });
        }

        // Get repository files
        const files = await getRepoFiles(`${repoOwner}/${repoName}`);
        console.log('Found files:', files.map(f => f.path));

        // Analyze code using Gemini
        const analysis = await analyzeWithAI(files, repoLanguage);
        console.log('Analysis completed:', analysis);

        if (analysis.issues && analysis.issues.length > 0) {
            // Create a new branch for fixes
            const defaultBranch = branch || 'main';
            const fixBranchName = `fix/${Date.now()}`;

            // Get the latest commit SHA from the default branch
            const { data: refData } = await octokit.git.getRef({
                owner: repoOwner,
                repo: repoName,
                ref: `heads/${defaultBranch}`
            });
            const latestCommitSha = refData.object.sha;

            // Create a new branch
            await octokit.git.createRef({
                owner: repoOwner,
                repo: repoName,
                ref: `refs/heads/${fixBranchName}`,
                sha: latestCommitSha
            });

            // Generate fixes for issues
            const fixes = await generateFixes(analysis, files, repoLanguage);

            // Apply fixes one by one
            for (const fix of fixes) {
                if (!fix || !fix.file) continue;

                try {
                    // Get the current file content
                    const { data: fileData } = await octokit.repos.getContent({
                        owner: repoOwner,
                        repo: repoName,
                        path: fix.file,
                        ref: fixBranchName
                    });

                    // Update the file with fixed content
                    await octokit.repos.createOrUpdateFileContents({
                        owner: repoOwner,
                        repo: repoName,
                        path: fix.file,
                        message: `fix: ${fix.issue.description}`,
                        content: Buffer.from(fix.fixedContent).toString('base64'),
                        branch: fixBranchName,
                        sha: fileData.sha
                    });
                } catch (err) {
                    console.error(`Error applying fix to ${fix.file}:`, err.message);
                }
            }

            // Create pull request
            const { data: pr } = await octokit.pulls.create({
                owner: repoOwner,
                repo: repoName,
                title: '[Scriptocol] Automated fixes',
                body: `This PR contains automated fixes generated by Scriptocol.

### Issues Fixed:
${analysis.issues.map(issue => `- **${issue.type}** (${issue.severity}): ${issue.description}
  - File: \`${issue.file}\` (lines ${issue.line})
  - Impact: ${issue.impact}
  - Fix: ${issue.suggestion}
`).join('\n')}`,
                head: fixBranchName,
                base: defaultBranch,
                labels: ['automated-pr', 'scriptocol']
            });

            return res.json({
                message: 'Analysis completed successfully',
                issues: analysis.issues,
                pr: pr,
                status: 'success'
            });
        } else {
            return res.json({
                message: 'No issues found',
                issues: [],
                status: 'success'
            });
        }
    } catch (error) {
        console.error('Error in analyze:', error);
        return res.status(500).json({ 
            error: error.message,
            status: 'error'
        });
    }
};

export async function getRepoFiles(repo) {
    try {
        // Ensure repo is in the format owner/repo
        if (!repo.includes('/')) {
            throw new Error('Repository must be in the format owner/repo');
        }

        console.log('Fetching contents for repository:', repo);
        const response = await axios.get(`https://api.github.com/repos/${repo}/contents`, {
            headers: {
                Authorization: `Bearer ${process.env.GITHUB_TOKEN}`,
                Accept: 'application/vnd.github.v3+json'
            }
        });
        
        console.log('Found files:', response.data.map(file => file.name));
        
        const files = [];
        for (const item of response.data) {
            if (item.type === 'file') {
                try {
                    const content = await axios.get(item.download_url);
                    files.push({
                        name: item.name,
                        path: item.path,
                        content: content.data
                    });
                } catch (error) {
                    console.error(`Error fetching content for ${item.path}:`, error.message);
                }
            } else if (item.type === 'dir') {
                // Recursively get contents of directories
                const dirFiles = await getDirectoryContents(repo, item.path);
                files.push(...dirFiles);
            }
        }
        
        return files;
    } catch (error) {
        console.error('Error getting repo files:', error);
        throw error;
    }
}

async function getDirectoryContents(repo, path) {
    try {
        const response = await axios.get(`https://api.github.com/repos/${repo}/contents/${path}`, {
            headers: {
                Authorization: `Bearer ${process.env.GITHUB_TOKEN}`,
                Accept: 'application/vnd.github.v3+json'
            }
        });

        const files = [];
        for (const item of response.data) {
            if (item.type === 'file') {
                try {
                    const content = await axios.get(item.download_url);
                    files.push({
                        name: item.name,
                        path: item.path,
                        content: content.data
                    });
                } catch (error) {
                    console.error(`Error fetching content for ${item.path}:`, error.message);
                }
            } else if (item.type === 'dir') {
                // Recursively get contents of subdirectories
                const dirFiles = await getDirectoryContents(repo, item.path);
                files.push(...dirFiles);
            }
        }
        return files;
    } catch (error) {
        console.error(`Error getting contents for directory ${path}:`, error);
        return [];
    }
}

export async function analyzeWithAI(files, lang) {
    try {
        // Filter to only include code files
        const codeFiles = files.filter(file => {
            const ext = file.path.split('.').pop().toLowerCase();
            return ['js', 'jsx', 'ts', 'tsx', 'py', 'go'].includes(ext);
        });

        // Process files in chunks of 2 to avoid token limits
        const issues = [];
        for (let i = 0; i < codeFiles.length; i += 2) {
            const chunk = codeFiles.slice(i, i + 2);
            const fileContents = chunk.map(file => `File: ${file.path}\n\`\`\`\n${file.content}\n\`\`\``).join('\n\n');
            
            const prompt = `Quickly analyze these ${lang} files for critical issues. Focus on:
1. Security vulnerabilities
2. Performance bottlenecks
3. Error handling gaps
4. Code quality issues

${fileContents}

Respond with a JSON array of issues in this format:
{
    "issues": [
        {
            "type": "security|performance|errorHandling|quality",
            "severity": "high|medium",
            "description": "brief issue description",
            "impact": "what could happen",
            "file": "exact file path",
            "line": "line numbers",
            "suggestion": "concrete fix",
            "example": "before/after code example"
        }
    ]
}`;

            try {
                // Call Gemini API directly using axios
                const payload = {
                    contents: [
                        {
                            role: "user",
                            parts: [{ text: prompt }]
                        }
                    ],
                    generationConfig: {
                        temperature: 0.2,
                        topP: 0.8,
                        topK: 40,
                        maxOutputTokens: 8192,
                        responseMimeType: "application/json"
                    }
                };

                const response = await axios.post(GEMINI_ANALYSIS_ENDPOINT, payload, {
                    headers: {
                        'Content-Type': 'application/json'
                    }
                });
                
                // Extract text from the response
                let responseText = '';
                try {
                    responseText = response.data.candidates[0].content.parts[0].text;
                } catch (e) {
                    console.warn('Unexpected response structure:', e.message);
                    continue;
                }
                
                // Advanced JSON extraction and parsing
                let jsonResponse;
                try {
                    // First attempt: clean up and parse the text directly
                    // Replace problematic escape sequences
                    const cleanedText = responseText
                        .replace(/\\\\/g, '\\') // Replace double backslashes with single
                        .replace(/\\(?!["\\/bfnrt])/g, '\\\\') // Escape unescaped backslashes
                        .replace(/\\x[0-9a-fA-F]{2}/g, '') // Remove hex escape sequences
                        .replace(/\r?\n/g, '\\n'); // Normalize newlines
                    
                    jsonResponse = JSON.parse(cleanedText);
                } catch (e1) {
                    console.warn('First JSON parse attempt failed:', e1.message);
                    
                    try {
                        // Second attempt: try to extract JSON using regex
                        const jsonMatch = responseText.match(/\{[\s\S]*\}/);
                        if (jsonMatch) {
                            // Clean up the extracted JSON
                            const extractedJson = jsonMatch[0]
                                .replace(/\\\\/g, '\\')
                                .replace(/\\(?!["\\/bfnrt])/g, '\\\\')
                                .replace(/\\x[0-9a-fA-F]{2}/g, '')
                                .replace(/\r?\n/g, '\\n');
                            
                            jsonResponse = JSON.parse(extractedJson);
                        } else {
                            throw new Error('No JSON object found in response');
                        }
                    } catch (e2) {
                        console.warn('Second JSON parse attempt failed:', e2.message);
                        
                        // Third attempt: Manual JSON construction
                        try {
                            // Try to find issue blocks with regex
                            const issueMatches = responseText.matchAll(/"type"\s*:\s*"([^"]+)"\s*,\s*"severity"\s*:\s*"([^"]+)"\s*,\s*"description"\s*:\s*"([^"]+)"\s*,\s*"impact"\s*:\s*"([^"]+)"\s*,\s*"file"\s*:\s*"([^"]+)"\s*,\s*"line"\s*:\s*"([^"]+)"\s*,\s*"suggestion"\s*:\s*"([^"]+)"\s*,\s*"example"\s*:\s*"([^"]+)"/g);
                            
                            const extractedIssues = [];
                            for (const match of issueMatches) {
                                extractedIssues.push({
                                    type: match[1],
                                    severity: match[2],
                                    description: match[3],
                                    impact: match[4],
                                    file: match[5],
                                    line: match[6],
                                    suggestion: match[7],
                                    example: match[8]
                                });
                            }
                            
                            jsonResponse = { issues: extractedIssues };
                        } catch (e3) {
                            console.warn('Third JSON parse attempt failed:', e3.message);
                            jsonResponse = { issues: [] };
                        }
                    }
                }

                if (jsonResponse && jsonResponse.issues) {
                    // Validate each issue has the required fields
                    const validIssues = jsonResponse.issues.filter(issue => 
                        issue.type && issue.severity && issue.description && issue.file);
                    
                    issues.push(...validIssues);
                }
            } catch (error) {
                console.error('Error processing chunk:', error.message);
                continue; // Continue with next chunk on error
            }
        }

        return { issues };
    } catch (error) {
        console.error('Error analyzing with AI:', error);
        throw error;
    }
}

async function generateFixes(analysis, files, lang) {
    try {
        const fixes = [];
        
        for (const issue of analysis.issues) {
            const file = files.find(f => f.path === issue.file);
            if (!file) continue;
            
            const prompt = `Fix the following issue in this ${lang} code:

Issue: ${issue.description}
Suggestion: ${issue.suggestion}

File: ${file.path}
\`\`\`
${file.content}
\`\`\`

Provide only the fixed code without explanations.`;

            // Call Gemini API directly using axios
            const payload = {
                contents: [
                    {
                        role: "user",
                        parts: [{ text: prompt }]
                    }
                ],
                generationConfig: {
                    temperature: 0.2,
                    topP: 0.8,
                    topK: 40,
                    maxOutputTokens: 8192
                }
            };

            try {
                const response = await axios.post(GEMINI_FIX_ENDPOINT, payload, {
                    headers: {
                        'Content-Type': 'application/json'
                    }
                });
                
                // Get the text from the response
                const fixedCode = response.data.candidates[0].content.parts[0].text.trim();
                
                fixes.push({
                    file: issue.file,
                    originalContent: file.content,
                    fixedContent: fixedCode,
                    issue: issue
                });
            } catch (err) {
                console.error(`Error generating fix for ${issue.file}:`, err.message);
            }
        }
        
        return fixes;
    } catch (error) {
        console.error('Error generating fixes:', error);
        return [];
    }
}